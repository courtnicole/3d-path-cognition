{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyxdf \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from lmfit.models import Model\n",
    "from os import listdir, getcwd\n",
    "from os.path import isfile, join\n",
    "from scipy import stats\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import pywt\n",
    "import math\n",
    "from pandas.api.types import CategoricalDtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pupillary Functions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task evoked pupillary response is calculated after correcting for luminance-induced pupil dilation: $𝑇𝐸𝑃𝑅 = 𝑑_m − 𝑑(𝑌)$, where $d_m$ is the measured pupil dilation, and $d(Y)$ is the predicted pupil dilation for the given luminance level. \n",
    "\n",
    "Predicted pupil dilation is calculated from a calibration sequence that produces and individual mapping model for each participant. The calibration sequence consists of 8 solid gray colors with varying luminance levels displayed in a psuedo-random order for 6 seconds each. The luminance levels span the range from 0.0 to 0.78, and for each calibration level, the first 0.5s of data is discarded to account for the initial pupillary response to the change in luminance, which can take a maximum of 0.5s. . The individual mapping model is calculated using a non-linear least squares regression to fit the equation $𝑑(𝑌) = 𝑎 · 𝑒^{−𝑏·𝑌} + c$ to the measured pupil dilation data for each participant. \n",
    "\n",
    "Pupil dilation data and the average luminance data were collected at 90 Hz, the display rate of the HMD.\n",
    "\n",
    "See: Eckert, M., Robotham, T., Habets, E. A. P., and Rummukainen, O. S. (2022). Pupillary Light Reflex Correction for Robust Pupillometry in Virtual Reality. Proc. ACM Comput. Graph. Interact. Tech. 5, 1–16. doi: 10.1145/3530798"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pupil_func(x, a, b, c):\n",
    "    return a * np.exp(-b * x) + c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modmax(d):\n",
    "    # compute signal modulus\n",
    "    m = [0.0]*len(d)\n",
    "    for i in range(len(d)):\n",
    "        m[i] = math.fabs(d[i])\n",
    "    # if value is larger than both neighbours , and strictly larger than either , then it is a local maximum\n",
    "    t = [0.0]*len(d)\n",
    "    for i in range(len(d)):\n",
    "        ll = m[i -1] if i >= 1 else m[i]\n",
    "        oo = m[i]\n",
    "        rr = m[i+1] if i < len(d)-2 else m[i]\n",
    "        if (ll <= oo and oo >= rr) and (ll < oo or oo > rr):\n",
    "        # compute magnitude\n",
    "            t[i] = math.sqrt(d[i]**2)\n",
    "        else:\n",
    "            t[i] = 0.0\n",
    "    return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ipa_func(d):\n",
    "    # obtain 2-level DWT of pupil diameter signal d\n",
    "    try:\n",
    "        (cA2 ,cD2 ,cD1) = pywt.wavedec(d,'sym16', 'per', level=2)\n",
    "    except ValueError :\n",
    "        return\n",
    "    # get signal duration (in seconds)\n",
    "    tt = d.index[-1] - d.index[0]\n",
    "    # normalize by 1/2 j , j = 2 for 2-level DWT\n",
    "    cA2 [:] = [x / math.sqrt (4.0) for x in cA2]\n",
    "    cD1 [:] = [x / math.sqrt (2.0) for x in cD1]\n",
    "    cD2 [:] = [x / math.sqrt (4.0) for x in cD2]\n",
    "\n",
    "    # detect modulus maxima , see Listing 2\n",
    "    cD2m = modmax(cD2)\n",
    "    # threshold using universal threshold λuniv = σˆp(2logn)\n",
    "    # where σˆ is the standard deviation of the noise\n",
    "    λuniv = np.std(cD2m) * math.sqrt (2.0* np.log2(len(cD2m )))\n",
    "    cD2t = pywt. threshold (cD2m ,λuniv,mode=\"hard\")\n",
    "    # compute IPA\n",
    "    ctr = 0\n",
    "    for i in range(len(cD2t )):\n",
    "        if math.fabs(cD2t[i]) > 0: ctr += 1\n",
    "    IPA = float(ctr)/tt.total_seconds()\n",
    "\n",
    "    return IPA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistical Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iqr_outlier_indices(data):\n",
    "    q1 = data.quantile(.25)\n",
    "    q3 = data.quantile(.75)\n",
    "    iqr = stats.iqr(data, nan_policy='omit', rng=(25, 75))\n",
    "    return np.where((data < (q1 - 1.5 * iqr)) | (data > (q3 + 1.5 * iqr)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iqr_stats(data):\n",
    "    q1 = np.percentile(data, 25)\n",
    "    q3 = np.percentile(data, 75)\n",
    "    iqr = stats.iqr(data, nan_policy='omit', rng=(25, 75))\n",
    "    return iqr, q1, q3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_results_colors(np, wp, tp):\n",
    "    pastels = px.colors.qualitative.Pastel2\n",
    "    default_color = 'white'\n",
    "    significant_color = pastels[0]\n",
    "    non_significant_color = pastels[3]\n",
    "\n",
    "    normal_color = non_significant_color if np < 0.05 else significant_color\n",
    "    wilcox_color = default_color\n",
    "    ttest_color = default_color\n",
    "    if np < 0.05:\n",
    "        wilcox_color = significant_color if wp < 0.05 else non_significant_color\n",
    "    else:\n",
    "        ttest_color = significant_color if tp < 0.05 else non_significant_color\n",
    "\n",
    "    fill_color = [[default_color, default_color, default_color],\n",
    "                  [default_color, wilcox_color, ttest_color] , \n",
    "                  [normal_color, wilcox_color, ttest_color]]\n",
    "    \n",
    "    return fill_color"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_data(file):\n",
    "    streams, header = pyxdf.load_xdf(file)\n",
    "    dfs = {}\n",
    "    for stream in streams:\n",
    "        stream_name = stream['info']['name'][0]\n",
    "        stream_channels = {channel['label'][0]: i for i, channel in enumerate(stream['info']['desc'][0]['channels'][0]['channel'])}\n",
    "        stream_data = stream['time_series']\n",
    "        data_dict = {key: np.array(stream_data)[:, index] for key, index in stream_channels.items()}\n",
    "        data_dict['time'] = np.round(np.array(stream['time_stamps']), decimals=4)\n",
    "        dfs[stream_name] = pd.DataFrame(data_dict).drop_duplicates(subset=['time']).reset_index(drop=True)\n",
    "    return dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "accom_time = pd.to_timedelta(0.5, unit='s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "method_cats = CategoricalDtype(['4DoF','6DoF', 'unimanual','bimanual'], ordered=False)\n",
    "model_cats = CategoricalDtype(['A', 'B', 'C', 'D'], ordered=True)\n",
    "block_cats = CategoricalDtype(['0', '1', '2', '3'], ordered=True)\n",
    "event_cats = CategoricalDtype(['Start', 'PointPlaced', 'Move', 'End', 'Draw', 'Erase', 'PointDeleted'])\n",
    "data_names = ['id', 'block', 'model', 'method']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_gaze_luminance_data(stream_df):\n",
    "    pupil = stream_df['GazeStream'].loc[(stream_df['GazeStream']['LeftEyeIsBlinking'] == 0) \n",
    "                                        & (stream_df['GazeStream']['RightEyeIsBlinking'] == 0) \n",
    "                                        & (stream_df['GazeStream']['LeftPupilDiameter'] > 0) \n",
    "                                        & (stream_df['GazeStream']['RightPupilDiameter'] > 0), \n",
    "                                        ['time', 'MethodID', 'ModelID', 'LeftPupilDiameter', 'RightPupilDiameter']]\n",
    "    pupil['time'] = pd.to_timedelta(pupil['time'], unit='s')\n",
    "\n",
    "    lum = stream_df['LuminanceStream'].loc[:, ['time', 'MethodID', 'ModelID', 'Luminance']]\n",
    "    lum['time'] = pd.to_timedelta(lum['time'], unit='s')\n",
    "\n",
    "    # Intersection of time stamps\n",
    "    pupil_lum_time_intersection = np.intersect1d(pupil['time'], lum['time'])\n",
    "\n",
    "    # Filter pupil and luminance data by intersection\n",
    "    pupil = pupil[pupil['time'].isin(pupil_lum_time_intersection)].reset_index(drop=True)\n",
    "    lum = lum[lum['time'].isin(pupil_lum_time_intersection)].reset_index(drop=True)\n",
    "\n",
    "    # Combined DataFrame for pupil and luminance\n",
    "    pupil_lum = pd.DataFrame({\n",
    "        'time': pd.to_timedelta(pupil_lum_time_intersection, unit='s'),\n",
    "        'luminance': lum['Luminance'],\n",
    "        'pupilDiameter': 0.5 * (pupil['LeftPupilDiameter'] + pupil['RightPupilDiameter']),\n",
    "        'methodID': pupil['MethodID'],\n",
    "        'modelID': pupil['ModelID']\n",
    "    })\n",
    "\n",
    "    outliers = iqr_outlier_indices(pupil_lum['pupilDiameter'])\n",
    "    pupil_lum = pupil_lum.drop(pupil_lum.iloc[outliers].index).reset_index(drop=True)\n",
    "\n",
    "    return pupil_lum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_calibration_data(pupil_lum_df, stream_df):\n",
    "    calibration_events = stream_df['ExperimentStream'].loc[(stream_df['ExperimentStream']['EventType'] == 'CalibrationColorChange') | \n",
    "                                                           (stream_df['ExperimentStream']['SceneEvent'] == 'Calibration') | \n",
    "                                                           (stream_df['ExperimentStream']['SceneEvent'] == 'CalibrationComplete'), \n",
    "                                                           ['time','SceneEvent', 'EventType']]\n",
    "    calibration_events['time'] = pd.to_timedelta(calibration_events['time'], unit='s')\n",
    "    c_start_times = calibration_events[:8]['time']\n",
    "    c_end_times = calibration_events[1:]['time']\n",
    "    c_start_times.reset_index(drop=True, inplace=True)\n",
    "    c_end_times.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    calib_data = {}\n",
    "    for i in range(8):\n",
    "        calib_data[i] = pupil_lum_df.loc[(pupil_lum_df['time'] >= c_start_times[i]) & (pupil_lum_df['time'] <= c_end_times[i]), ['time','luminance', 'pupilDiameter']]\n",
    "        calib_data[i]['time'] -= calib_data[i]['time'].iloc[0]\n",
    "        calib_data[i] = calib_data[i].loc[(calib_data[i]['time'] >= accom_time), ['luminance', 'pupilDiameter']]\n",
    "\n",
    "    calibration_data = pd.concat(calib_data).groupby(level=0).mean().sort_values(by=['luminance']).reset_index(drop=True)\n",
    "    return calibration_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_navigation_data(pupil_lum_df, stream_df, a, b, c):\n",
    "    grouped_data = stream_df['NavigationStream'].groupby(['ModelID', 'MethodID'])\n",
    "\n",
    "    stream_df['SurveyStream']['ModelID'] = stream_df['SurveyStream']['ModelID'].astype(float)\n",
    "    stream_df['SurveyStream']['MethodID'] = stream_df['SurveyStream']['MethodID'].astype(float)\n",
    "    \n",
    "    discomfort_survey = stream_df['SurveyStream'].loc[\n",
    "        (stream_df['SurveyStream']['SurveyType'] == 'Discomfort') & \n",
    "        (stream_df['SurveyStream']['ModelID'] < 4), \n",
    "        ['time', 'ModelID', 'MethodID']]\n",
    "    survey_group = discomfort_survey.groupby(['ModelID', 'MethodID'])\n",
    "\n",
    "    start_times = []\n",
    "    end_times = []\n",
    "    total_time = []\n",
    "\n",
    "    for i in range(4):\n",
    "        for j in range(2,4):\n",
    "            trial = grouped_data.get_group((i, j))\n",
    "\n",
    "            start = trial.loc[(trial['spline_percent'] > 0.001)].index[0]\n",
    "            start_time = pd.to_timedelta(stream_df['NavigationStream'].loc[start, 'time'], unit='s')\n",
    "\n",
    "            end = trial.loc[(trial['spline_percent'] > 0.995)]\n",
    "            end_time = 0\n",
    "            # For 6DoF navigation, completion was determined by collision with bounding box\n",
    "            # Spline percentage was based on projection, so it may not reach > 0.995.\n",
    "            # In this case, the survey time serves as the end time (rather than lowering the threshold)\n",
    "            if len(end) > 0:\n",
    "                end = end.index[0]\n",
    "                end_time = pd.to_timedelta(stream_df['NavigationStream'].loc[end, 'time'], unit='s')\n",
    "            else:\n",
    "                end = survey_group.get_group((i, j)).index[0]\n",
    "                end_time = pd.to_timedelta(stream_df['SurveyStream'].loc[end, 'time'], unit='s') - pd.offsets.Second(3)\n",
    "            \n",
    "            start_times.append(start_time)\n",
    "            end_times.append(end_time)\n",
    "            total_time.append((end_time - start_time).total_seconds())\n",
    "\n",
    "\n",
    "    nav_start_times = start_times\n",
    "    nav_end_times = end_times\n",
    "\n",
    "    nav_data = {}\n",
    "    for i in range(8):\n",
    "        nav_data[i] = pupil_lum_df.loc[\n",
    "            (pupil_lum_df['luminance'] >0) & \n",
    "            (pupil_lum_df['time']>nav_start_times[i]) & \n",
    "            (pupil_lum_df['time']<nav_end_times[i]), \n",
    "            ['time', 'methodID', 'modelID', 'luminance', 'pupilDiameter']]\n",
    "        nav_data[i].reset_index(drop=True, inplace=True)\n",
    "\n",
    "    navigation_data = pd.concat(nav_data, names=['trial'])\n",
    "    navigation_data['pupil_lum_base'] = pupil_func(navigation_data['luminance'], a, b, c)\n",
    "    navigation_data['adj_pupil'] = navigation_data['pupilDiameter'] - navigation_data['pupil_lum_base']\n",
    "\n",
    "    return navigation_data, total_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_creation_data(pupil_lum_df, stream_df, a, b, c):\n",
    "    \n",
    "    crt_start_times = stream_df['CreationStream'].loc[\n",
    "    (stream_df['CreationStream']['EventName'] == 'StartPointRegistered'), ['time', 'ModelID', 'MethodID']]\n",
    "    crt_start_times = pd.to_timedelta(crt_start_times.groupby(['ModelID', 'MethodID']).first()['time'], unit='s') + pd.offsets.Second(2)\n",
    "    crt_start_times.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    crt_end_times = stream_df['CreationStream'].loc[(stream_df['CreationStream']['EventName'] == 'FinishPath'), ['time', 'ModelID', 'MethodID']]\n",
    "    crt_end_times = pd.to_timedelta(crt_end_times.groupby(['ModelID', 'MethodID']).first()['time'], unit='s')\n",
    "    crt_end_times.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    total_time = crt_end_times - crt_start_times\n",
    "    total_time = total_time.apply(lambda x: x.total_seconds())\n",
    "\n",
    "    crt_data = {}\n",
    "    for i in range(8):\n",
    "        crt_data[i] = pupil_lum_df.loc[\n",
    "            (pupil_lum_df['time'] > crt_start_times.loc[i]) & \n",
    "            (pupil_lum_df['time'] < crt_end_times.loc[i]), \n",
    "            ['time', 'methodID', 'modelID', 'luminance', 'pupilDiameter']]\n",
    "        crt_data[i].reset_index(drop=True, inplace=True)\n",
    "\n",
    "    creation_data = pd.concat(crt_data, names=['trial'])\n",
    "    creation_data['pupil_lum_base'] = pupil_func(creation_data['luminance'], a, b, c)\n",
    "    creation_data['adj_pupil'] = creation_data['pupilDiameter'] - creation_data['pupil_lum_base']\n",
    "    \n",
    "    return creation_data, total_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_creation_stats(stream_df):\n",
    "    \n",
    "    group = stream_df['CreationStream'].groupby(['ModelID', 'MethodID'])\n",
    "    creation_counts  = []\n",
    "\n",
    "    for i in range(4):\n",
    "            for j in range(0,2):\n",
    "                trial = group.get_group((i,j))\n",
    "                creation_counts.append(trial.groupby('EventType', observed=False).size().fillna(0))\n",
    "    \n",
    "    keys = [(i,j) for i in range(4) for j in range(0,2)]\n",
    "    creation_stats = pd.concat(creation_counts, axis=0, keys=keys, names=['ModelID', 'MethodID']).unstack(level=2)\n",
    "    creation_stats = creation_stats.drop(columns=['End', 'Start'])\n",
    "    return creation_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_discomfort_data(stream_df):\n",
    "    discomfort_values = stream_df['SurveyStream'].loc[stream_df['SurveyStream']['SurveyType'] == 'Discomfort', ['time', 'Value', 'ModelID', 'MethodID']]\n",
    "    discomfort_values['time'] = pd.to_timedelta(discomfort_values['time'], unit='s')\n",
    "    discomfort_values.reset_index(drop=True, inplace=True)\n",
    "    return discomfort_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_seq_data(stream_df):\n",
    "    seq_values = stream_df['SurveyStream'].loc[stream_df['SurveyStream']['SurveyType'] == 'SEQ', ['time', 'Value', 'ModelID', 'MethodID']]\n",
    "    seq_values['time'] = pd.to_timedelta(seq_values['time'], unit='s')\n",
    "    seq_values.reset_index(drop=True, inplace=True)\n",
    "    return seq_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_ipa_calc(data):\n",
    "    methods = []\n",
    "    models = []\n",
    "    ipa = []\n",
    "    for i in range(8):\n",
    "        methods.append(data.loc[i]['methodID'].iloc[i])\n",
    "        models.append(data.loc[i]['modelID'].iloc[i])\n",
    "        pupil = data.loc[i]['pupilDiameter']\n",
    "        pupil.index = data.loc[i]['time']\n",
    "        ipa.append(ipa_func(pupil))\n",
    "        \n",
    "    return pd.DataFrame({'methodID': methods, 'modelID': models, 'IPA': ipa})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = join(getcwd(),'Path_Data')\n",
    "data_files = [join(data_dir, f) for f in listdir(data_dir) if isfile(join(data_dir, f))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = []\n",
    "for file in data_files:\n",
    "    dfs.append(import_data(file))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_dfs_nav = []\n",
    "user_dfs_crt = []\n",
    "ids = []\n",
    "blocks = []\n",
    "\n",
    "for df in dfs:\n",
    "    id = df['ExperimentStream']['UserID'][0]\n",
    "    block = df['ExperimentStream']['BlockID'][0]\n",
    "    ids.append(id)\n",
    "    blocks.append(block)\n",
    "\n",
    "    # Remove final empty row from string data streams\n",
    "    df['SurveyStream'] = df['SurveyStream'].replace(r'^\\s*$', np.nan, regex=True).dropna()\n",
    "    df['CreationStream'] = df['CreationStream'].replace(r'^\\s*$', np.nan, regex=True).dropna()\n",
    "\n",
    "    df['SurveyStream']['ModelID'] = df['SurveyStream']['ModelID'].astype(float)\n",
    "    df['SurveyStream']['MethodID'] = df['SurveyStream']['MethodID'].astype(float)\n",
    "    df['SurveyStream']['Value'] = df['SurveyStream']['Value'].astype(float)\n",
    "\n",
    "    df['CreationStream']['ModelID'] = df['CreationStream']['ModelID'].astype(float)\n",
    "    df['CreationStream']['MethodID'] = df['CreationStream']['MethodID'].astype(float)\n",
    "    df['CreationStream']['EventType'] = df['CreationStream']['EventType'].astype(event_cats)\n",
    "\n",
    "    pupil_lum_df = process_gaze_luminance_data(df)\n",
    "    calibration_data = process_calibration_data(pupil_lum_df, df)\n",
    "\n",
    "    # Fit pupil response to luminance\n",
    "    x_data = calibration_data['luminance']\n",
    "    y_data = calibration_data['pupilDiameter']\n",
    "    exp_mod = Model(pupil_func)\n",
    "    params = exp_mod.make_params(a=1, b=4, c=0)\n",
    "    result = exp_mod.fit(y_data, params, x=x_data)\n",
    "    a = result.params['a'].value\n",
    "    b = result.params['b'].value\n",
    "    c = result.params['c'].value\n",
    "\n",
    "    navigation_data, nav_time = process_navigation_data(pupil_lum_df, df, a, b, c)\n",
    "    ipa_calc_nav = process_ipa_calc(navigation_data)\n",
    "    creation_data, crt_time = process_creation_data(pupil_lum_df, df, a, b, c)\n",
    "    ipa_calc_crt = process_ipa_calc(creation_data)\n",
    "    creation_stats = process_creation_stats(df)\n",
    "    discomfort = process_discomfort_data(df)\n",
    "    seq = process_seq_data(df)\n",
    "\n",
    "    nav_trials = navigation_data.groupby(['modelID', 'methodID'])\n",
    "    ipa_nav_trials = ipa_calc_nav.groupby(['modelID', 'methodID'])\n",
    "    crt_trials = creation_data.groupby(['modelID', 'methodID'])\n",
    "    ipa_crt_trials = ipa_calc_crt.groupby(['modelID', 'methodID'])\n",
    "    discomfort_trials = discomfort.groupby(['ModelID', 'MethodID'])\n",
    "    seq_trials = seq.groupby(['ModelID', 'MethodID'])\n",
    "\n",
    "    nav_data = {}\n",
    "    nav_total_time = {}\n",
    "    ipa_nav_data = {}\n",
    "    crt_data = {}\n",
    "    crt_total_time = {}\n",
    "    ipa_crt_data = {}\n",
    "    discomfort_data = {}\n",
    "    seq_crt = {}\n",
    "    seq_nav = {}\n",
    "\n",
    "    for i in range(4):\n",
    "        for j in range(2,4):\n",
    "            nav_data[(id, block, i, j)] = nav_trials.get_group((i,j)).mean()\n",
    "            nav_total_time[(id, block, i, j)] = nav_time[(2*i + (j-2))]\n",
    "            ipa_nav_data[(id, block, i, j)] = ipa_nav_trials.get_group((i,j)).mean()\n",
    "            discomfort_data[(id, block, i, j)] = discomfort_trials.get_group((i,j)).mean()\n",
    "            seq_nav[(id, block, i, j)] = seq_trials.get_group((i,j)).mean()\n",
    "    \n",
    "    for i in range(4):\n",
    "        for j in range(0,2):\n",
    "            crt_data[(id, block, i, j)] = crt_trials.get_group((i,j)).mean()\n",
    "            crt_total_time[(id, block, i, j)] = crt_time[(2*i + j)]\n",
    "            ipa_crt_data[(id, block, i, j)] = ipa_crt_trials.get_group((i,j)).mean()\n",
    "            seq_crt[(id, block, i, j)] = seq_trials.get_group((i,j)).mean()\n",
    "    \n",
    "    nav_index = pd.MultiIndex.from_product([[id], [block], model_cats.categories, method_cats.categories[0:2]], names=data_names)\n",
    "    crt_index = pd.MultiIndex.from_product([[id], [block], model_cats.categories, method_cats.categories[2:4]], names=data_names)\n",
    "\n",
    "    nav_data = pd.concat(nav_data, axis=1, names=data_names).T\n",
    "    nav_data['total_time'] = nav_total_time\n",
    "    nav_data.index = nav_index\n",
    "    nav_data.drop(columns=['time', 'modelID', 'methodID'], inplace=True)\n",
    "    \n",
    "    crt_data = pd.concat(crt_data, axis=1, names=data_names).T\n",
    "    crt_data['total_time'] = crt_total_time\n",
    "    crt_data.index = crt_index\n",
    "    crt_data.drop(columns=['time', 'modelID', 'methodID'], inplace=True)\n",
    "\n",
    "    creation_stats.index = crt_index\n",
    "\n",
    "    ipa_nav_data = pd.concat(ipa_nav_data, axis=1, names=data_names).T\n",
    "    ipa_nav_data.index = nav_index\n",
    "    ipa_nav_data.drop(columns=['modelID', 'methodID'], inplace=True)\n",
    "\n",
    "    ipa_crt_data = pd.concat(ipa_crt_data, axis=1, names=data_names).T\n",
    "    ipa_crt_data.index = crt_index\n",
    "    ipa_crt_data.drop(columns=['modelID', 'methodID'], inplace=True)\n",
    "\n",
    "    discomfort_data = pd.concat(discomfort_data, axis=1, names=data_names).T\n",
    "    discomfort_data.index = nav_index\n",
    "    discomfort_data['discomfort'] = discomfort_data['Value']\n",
    "    discomfort_data.drop(columns=['time', 'ModelID', 'MethodID', 'Value'], inplace=True)\n",
    "\n",
    "    seq_nav = pd.concat(seq_nav, axis=1, names=data_names).T\n",
    "    seq_nav.index = nav_index\n",
    "    seq_nav['seq'] = seq_nav['Value']\n",
    "    seq_nav.drop(columns=['time', 'ModelID', 'MethodID', 'Value'], inplace=True)\n",
    "\n",
    "    seq_crt = pd.concat(seq_crt, axis=1, names=data_names).T\n",
    "    seq_crt.index = crt_index\n",
    "    seq_crt['seq'] = seq_crt['Value']\n",
    "    seq_crt.drop(columns=['time', 'ModelID', 'MethodID', 'Value'], inplace=True)\n",
    "\n",
    "    df_crt = pd.concat([crt_data, ipa_crt_data, seq_crt, creation_stats], axis=0).stack().unstack()\n",
    "    df_crt.loc[(slice(None), slice(None), slice(None), slice(None)), ('Draw', 'Erase', 'PointPlaced', 'Move', 'PointDeleted')] = df_crt.loc[(slice(None), slice(None), slice(None), slice(None)), ('Draw', 'Erase', 'PointPlaced', 'Move', 'PointDeleted')].astype(int)\n",
    "    df_crt.loc[(slice(None), slice(None), slice(None), 'unimanual'), ('Draw', 'Erase')] = df_crt.loc[(slice(None), slice(None), slice(None), 'unimanual'), ('Draw', 'Erase')].astype(int).fillna(0)\n",
    "    df_crt.loc[(slice(None), slice(None), slice(None), 'bimanual'), ('PointPlaced', 'Move', 'PointDeleted')] = df_crt.loc[(slice(None), slice(None), slice(None), 'bimanual'), ('PointPlaced', 'Move', 'PointDeleted')].astype(int).fillna(0)\n",
    "\n",
    "    df_nav = pd.concat([nav_data, ipa_nav_data, discomfort_data, seq_nav], axis=0).stack().unstack()\n",
    "\n",
    "    user_dfs_nav.append(df_nav)\n",
    "    user_dfs_crt.append(df_crt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_data_nav = pd.concat(user_dfs_nav)\n",
    "nav_dtype = {'luminance': 'float64', 'pupilDiameter': 'float64', 'pupil_lum_base': 'float64', 'adj_pupil': 'float64', 'IPA': 'float64', 'discomfort': 'int32', 'seq': 'int32', 'total_time': 'float64'}\n",
    "user_data_nav = user_data_nav.astype(nav_dtype)\n",
    "\n",
    "short_nav = user_data_nav['total_time'] < 10\n",
    "user_data_nav = user_data_nav[~short_nav]\n",
    "\n",
    "user_data_crt = pd.concat(user_dfs_crt)\n",
    "crt_dtype = {'luminance' : 'float64', 'pupilDiameter' : 'float64', 'pupil_lum_base' : 'float64', 'adj_pupil' : 'float64', 'IPA' : 'float64', 'seq' : 'int32', 'PointPlaced' : 'int32', 'Move' : 'int32', 'Draw' : 'int32', 'Erase' : 'int32', 'PointDeleted' : 'int32', 'total_time': 'float64'}\n",
    "user_data_crt = user_data_crt.astype(crt_dtype)\n",
    "\n",
    "short_crt = user_data_crt['total_time'] < 10\n",
    "user_data_crt = user_data_crt[~short_crt]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mixed Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>block</th>\n",
       "      <th>model</th>\n",
       "      <th>method</th>\n",
       "      <th>luminance</th>\n",
       "      <th>pupilDiameter</th>\n",
       "      <th>pupil_lum_base</th>\n",
       "      <th>adj_pupil</th>\n",
       "      <th>total_time</th>\n",
       "      <th>IPA</th>\n",
       "      <th>discomfort</th>\n",
       "      <th>seq</th>\n",
       "      <th>scaled_tepr</th>\n",
       "      <th>scaled_ipa</th>\n",
       "      <th>scaled_time</th>\n",
       "      <th>scaled_seq</th>\n",
       "      <th>scaled_discomfort</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>190.00000</td>\n",
       "      <td>190.00000</td>\n",
       "      <td>190.00000</td>\n",
       "      <td>190.00000</td>\n",
       "      <td>190.00000</td>\n",
       "      <td>190.00000</td>\n",
       "      <td>190.00000</td>\n",
       "      <td>190.00000</td>\n",
       "      <td>190.00000</td>\n",
       "      <td>190.00000</td>\n",
       "      <td>190.00000</td>\n",
       "      <td>190.00000</td>\n",
       "      <td>190.00000</td>\n",
       "      <td>190.00000</td>\n",
       "      <td>190.00000</td>\n",
       "      <td>190.00000</td>\n",
       "      <td>190.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>121.99474</td>\n",
       "      <td>1.34211</td>\n",
       "      <td>1.48947</td>\n",
       "      <td>0.50526</td>\n",
       "      <td>0.22543</td>\n",
       "      <td>3.67448</td>\n",
       "      <td>3.19926</td>\n",
       "      <td>0.47522</td>\n",
       "      <td>66.71027</td>\n",
       "      <td>0.17402</td>\n",
       "      <td>2.24737</td>\n",
       "      <td>0.71579</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>-0.00000</td>\n",
       "      <td>-0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>8.67612</td>\n",
       "      <td>1.14726</td>\n",
       "      <td>1.12094</td>\n",
       "      <td>0.50129</td>\n",
       "      <td>0.02232</td>\n",
       "      <td>0.49610</td>\n",
       "      <td>0.48409</td>\n",
       "      <td>0.28883</td>\n",
       "      <td>24.66471</td>\n",
       "      <td>0.05669</td>\n",
       "      <td>2.38311</td>\n",
       "      <td>0.89281</td>\n",
       "      <td>1.00264</td>\n",
       "      <td>1.00264</td>\n",
       "      <td>1.00264</td>\n",
       "      <td>1.00264</td>\n",
       "      <td>1.00264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>108.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.15815</td>\n",
       "      <td>2.81509</td>\n",
       "      <td>2.31899</td>\n",
       "      <td>-0.12002</td>\n",
       "      <td>24.18710</td>\n",
       "      <td>0.05486</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>-2.06630</td>\n",
       "      <td>-2.10744</td>\n",
       "      <td>-1.72860</td>\n",
       "      <td>-0.80385</td>\n",
       "      <td>-0.94553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>114.50000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.25000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.21228</td>\n",
       "      <td>3.28657</td>\n",
       "      <td>2.90119</td>\n",
       "      <td>0.23195</td>\n",
       "      <td>49.17595</td>\n",
       "      <td>0.13097</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>-0.84446</td>\n",
       "      <td>-0.76147</td>\n",
       "      <td>-0.71279</td>\n",
       "      <td>-0.80385</td>\n",
       "      <td>-0.94553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>121.50000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.22415</td>\n",
       "      <td>3.56740</td>\n",
       "      <td>3.08834</td>\n",
       "      <td>0.46525</td>\n",
       "      <td>60.06025</td>\n",
       "      <td>0.16950</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>-0.03460</td>\n",
       "      <td>-0.08000</td>\n",
       "      <td>-0.27033</td>\n",
       "      <td>-0.80385</td>\n",
       "      <td>-0.52480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>130.25000</td>\n",
       "      <td>2.00000</td>\n",
       "      <td>2.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.23880</td>\n",
       "      <td>4.04028</td>\n",
       "      <td>3.44560</td>\n",
       "      <td>0.70100</td>\n",
       "      <td>79.62245</td>\n",
       "      <td>0.20954</td>\n",
       "      <td>4.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.78375</td>\n",
       "      <td>0.62802</td>\n",
       "      <td>0.52489</td>\n",
       "      <td>0.31917</td>\n",
       "      <td>0.73738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>136.00000</td>\n",
       "      <td>3.00000</td>\n",
       "      <td>3.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.29142</td>\n",
       "      <td>5.20517</td>\n",
       "      <td>4.24519</td>\n",
       "      <td>1.26835</td>\n",
       "      <td>172.93840</td>\n",
       "      <td>0.34251</td>\n",
       "      <td>9.00000</td>\n",
       "      <td>4.00000</td>\n",
       "      <td>2.75324</td>\n",
       "      <td>2.97970</td>\n",
       "      <td>4.31827</td>\n",
       "      <td>3.68824</td>\n",
       "      <td>2.84102</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id     block     model    method  luminance  pupilDiameter  \\\n",
       "count 190.00000 190.00000 190.00000 190.00000  190.00000      190.00000   \n",
       "mean  121.99474   1.34211   1.48947   0.50526    0.22543        3.67448   \n",
       "std     8.67612   1.14726   1.12094   0.50129    0.02232        0.49610   \n",
       "min   108.00000   0.00000   0.00000   0.00000    0.15815        2.81509   \n",
       "25%   114.50000   0.00000   0.25000   0.00000    0.21228        3.28657   \n",
       "50%   121.50000   1.00000   1.00000   1.00000    0.22415        3.56740   \n",
       "75%   130.25000   2.00000   2.00000   1.00000    0.23880        4.04028   \n",
       "max   136.00000   3.00000   3.00000   1.00000    0.29142        5.20517   \n",
       "\n",
       "       pupil_lum_base  adj_pupil  total_time       IPA  discomfort       seq  \\\n",
       "count       190.00000  190.00000   190.00000 190.00000   190.00000 190.00000   \n",
       "mean          3.19926    0.47522    66.71027   0.17402     2.24737   0.71579   \n",
       "std           0.48409    0.28883    24.66471   0.05669     2.38311   0.89281   \n",
       "min           2.31899   -0.12002    24.18710   0.05486     0.00000   0.00000   \n",
       "25%           2.90119    0.23195    49.17595   0.13097     0.00000   0.00000   \n",
       "50%           3.08834    0.46525    60.06025   0.16950     1.00000   0.00000   \n",
       "75%           3.44560    0.70100    79.62245   0.20954     4.00000   1.00000   \n",
       "max           4.24519    1.26835   172.93840   0.34251     9.00000   4.00000   \n",
       "\n",
       "       scaled_tepr  scaled_ipa  scaled_time  scaled_seq  scaled_discomfort  \n",
       "count    190.00000   190.00000    190.00000   190.00000          190.00000  \n",
       "mean       0.00000     0.00000      0.00000    -0.00000           -0.00000  \n",
       "std        1.00264     1.00264      1.00264     1.00264            1.00264  \n",
       "min       -2.06630    -2.10744     -1.72860    -0.80385           -0.94553  \n",
       "25%       -0.84446    -0.76147     -0.71279    -0.80385           -0.94553  \n",
       "50%       -0.03460    -0.08000     -0.27033    -0.80385           -0.52480  \n",
       "75%        0.78375     0.62802      0.52489     0.31917            0.73738  \n",
       "max        2.75324     2.97970      4.31827     3.68824            2.84102  "
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mm_nav_data = user_data_nav\n",
    "mm_nav_data = mm_nav_data.reset_index(level=(0,1,2, 3))\n",
    "\n",
    "mm_nav_data['block'] = mm_nav_data['block'].astype(block_cats).cat.codes\n",
    "mm_nav_data['method'] = mm_nav_data['method'].astype(method_cats).cat.codes\n",
    "mm_nav_data['model'] = mm_nav_data['model'].astype(model_cats).cat.codes\n",
    "\n",
    "mm_nav_data['id'] = mm_nav_data['id'] .astype('int32')\n",
    "mm_nav_data['scaled_tepr'] = stats.zscore(mm_nav_data['adj_pupil']).astype('float64')\n",
    "mm_nav_data['scaled_ipa'] = stats.zscore(mm_nav_data['IPA']).astype('float64')\n",
    "mm_nav_data['scaled_time'] = stats.zscore(mm_nav_data['total_time']).astype('float64')\n",
    "mm_nav_data['scaled_seq'] = stats.zscore(mm_nav_data['seq']).astype('float64')\n",
    "mm_nav_data['scaled_discomfort'] = stats.zscore(mm_nav_data['discomfort']).astype('float64')\n",
    "\n",
    "pd.options.display.float_format = '{:.5f}'.format\n",
    "mm_nav_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Responses: IPA\n",
    "# Fixed: Method\n",
    "# Controlling for time on task?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Mixed Linear Model Regression Results\n",
      "=============================================================\n",
      "Model:               MixedLM  Dependent Variable:  scaled_ipa\n",
      "No. Observations:    190      Method:              REML      \n",
      "No. Groups:          24       Scale:               0.5851    \n",
      "Min. group size:     7        Log-Likelihood:      -244.5087 \n",
      "Max. group size:     8        Converged:           Yes       \n",
      "Mean group size:     7.9                                     \n",
      "-------------------------------------------------------------\n",
      "                   Coef.  Std.Err.   z    P>|z| [0.025 0.975]\n",
      "-------------------------------------------------------------\n",
      "Intercept           0.139    0.173  0.800 0.424 -0.201  0.479\n",
      "C(method)[T.1]     -0.284    0.113 -2.514 0.012 -0.506 -0.063\n",
      "C(model)[T.1]       0.009    0.156  0.055 0.956 -0.297  0.315\n",
      "C(model)[T.2]       0.060    0.157  0.382 0.703 -0.248  0.368\n",
      "C(model)[T.3]      -0.069    0.157 -0.437 0.662 -0.376  0.239\n",
      "Group Var           0.355    0.219                           \n",
      "Group x method Cov  0.062    0.129                           \n",
      "method Var          0.011    0.163                           \n",
      "=============================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\court\\anaconda3\\envs\\path_data\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "c:\\Users\\court\\anaconda3\\envs\\path_data\\Lib\\site-packages\\statsmodels\\regression\\mixed_linear_model.py:2201: ConvergenceWarning: Retrying MixedLM optimization with lbfgs\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "md = smf.mixedlm(\"scaled_ipa ~ C(method) + C(model)\", mm_nav_data, groups=mm_nav_data[\"id\"], re_formula=\"~method\")\n",
    "mdf = md.fit()\n",
    "print(mdf.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Mixed Linear Model Regression Results\n",
      "=============================================================\n",
      "Model:               MixedLM  Dependent Variable:  scaled_seq\n",
      "No. Observations:    190      Method:              REML      \n",
      "No. Groups:          24       Scale:               0.2697    \n",
      "Min. group size:     7        Log-Likelihood:      -201.2873 \n",
      "Max. group size:     8        Converged:           Yes       \n",
      "Mean group size:     7.9                                     \n",
      "-------------------------------------------------------------\n",
      "                   Coef.  Std.Err.   z    P>|z| [0.025 0.975]\n",
      "-------------------------------------------------------------\n",
      "Intercept          -0.128    0.155 -0.825 0.409 -0.431  0.176\n",
      "C(method)[T.1]      0.660    0.189  3.488 0.000  0.289  1.031\n",
      "C(model)[T.1]      -0.211    0.106 -1.986 0.047 -0.418 -0.003\n",
      "C(model)[T.2]      -0.330    0.107 -3.091 0.002 -0.539 -0.121\n",
      "C(model)[T.3]      -0.264    0.107 -2.477 0.013 -0.474 -0.055\n",
      "Group Var           0.406    0.294                           \n",
      "Group x method Cov -0.123    0.271                           \n",
      "method Var          0.722    0.525                           \n",
      "=============================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "md = smf.mixedlm(\"scaled_seq ~ C(method) + C(model)\", mm_nav_data, groups=mm_nav_data[\"id\"], re_formula=\"~method\")\n",
    "mdf = md.fit()\n",
    "print(mdf.summary())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

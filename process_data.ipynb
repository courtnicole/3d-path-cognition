{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyxdf \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from lmfit.models import Model\n",
    "from os import listdir, getcwd\n",
    "from os.path import isfile, join\n",
    "from scipy import stats\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import pywt\n",
    "import math\n",
    "from pandas.api.types import CategoricalDtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pupillary Functions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task evoked pupillary response is calculated after correcting for luminance-induced pupil dilation: $𝑇𝐸𝑃𝑅 = 𝑑_m − 𝑑(𝑌)$, where $d_m$ is the measured pupil dilation, and $d(Y)$ is the predicted pupil dilation for the given luminance level. \n",
    "\n",
    "Predicted pupil dilation is calculated from a calibration sequence that produces and individual mapping model for each participant. The calibration sequence consists of 8 solid gray colors with varying luminance levels displayed in a psuedo-random order for 6 seconds each. The luminance levels span the range from 0.0 to 0.78, and for each calibration level, the first 0.5s of data is discarded to account for the initial pupillary response to the change in luminance, which can take a maximum of 0.5s. . The individual mapping model is calculated using a non-linear least squares regression to fit the equation $𝑑(𝑌) = 𝑎 · 𝑒^{−𝑏·𝑌} + c$ to the measured pupil dilation data for each participant. \n",
    "\n",
    "Pupil dilation data and the average luminance data were collected at 90 Hz, the display rate of the HMD.\n",
    "\n",
    "See: Eckert, M., Robotham, T., Habets, E. A. P., and Rummukainen, O. S. (2022). Pupillary Light Reflex Correction for Robust Pupillometry in Virtual Reality. Proc. ACM Comput. Graph. Interact. Tech. 5, 1–16. doi: 10.1145/3530798"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pupil_func(x, a, b, c):\n",
    "    return a * np.exp(-b * x) + c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Index of Pupillary Activity (IPA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The frequency of pupil diameter oscilation over time is an indicator of cognitive load measured as the index of pupillary activity (IPA). It is an open-source alternative to the Index of Cognitive Activity. The IPA is implemented as described in the original paper, using a wavelet decomposition of the pupil diameter. The wavelet function is symlet8, because the signal was sampled at 90 Hz (rather than 250 Hz, as in the original paper).  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See: \n",
    "Duchowski, A. T., Krejtz, K., Krejtz, I., Biele, C., Niedzielska, A., Kiefer, P., Raubal, M., and Giannopoulos, I. (2018). The Index of Pupillary Activity: Measuring Cognitive Load vis-à-vis Task Difficulty with Pupil Oscillation. Proc. ACM Hum.-Comput. Interact. 2, 282:1–282:13. doi: 10.1145/3173574.3173856"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modmax(d):\n",
    "\n",
    "    # compute signal modulus\n",
    "    m = [0.0]*len(d)\n",
    "    for i in range(len(d)):\n",
    "        m[i] = math.fabs(d[i])\n",
    "\n",
    "    # if value is larger than both neighbours, and strictly larger than either, then it is a local maximum\n",
    "    t = [0.0]*len(d)\n",
    "    for i in range(len(d)):\n",
    "        ll = m[i - 1] if i >= 1 else m[i]\n",
    "        oo = m[i]\n",
    "        rr = m[i+1] if i < len(d)-2 else m[i]\n",
    "        if (ll <= oo and oo >= rr) and (ll < oo or oo > rr):\n",
    "        # compute magnitude\n",
    "            t[i] = math.sqrt(d[i]**2)\n",
    "        else:\n",
    "            t[i] = 0.0\n",
    "    return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ipa_func(d):\n",
    "    # obtain 2-level DWT of pupil diameter signal d\n",
    "    try:\n",
    "        (cA2 ,cD2 ,cD1) = pywt.wavedec(d,'sym8', 'per', level=2)\n",
    "    except ValueError :\n",
    "        return\n",
    "    # get signal duration (in seconds)\n",
    "    tt = d.index[-1] - d.index[0]\n",
    "    # normalize by 1/2 j, j = 2 for 2-level DWT\n",
    "    cA2 [:] = [x / math.sqrt (4.0) for x in cA2]\n",
    "    cD1 [:] = [x / math.sqrt (2.0) for x in cD1]\n",
    "    cD2 [:] = [x / math.sqrt (4.0) for x in cD2]\n",
    "\n",
    "    # detect modulus maxima\n",
    "    cD2m = modmax(cD2)\n",
    "    \n",
    "    # threshold using universal threshold univ = sqrt(oˆp(2logn)\n",
    "    # where o is the standard deviation of the noise\n",
    "    univ = np.std(cD2m) * math.sqrt (2.0 * np.log2(len(cD2m )))\n",
    "    cD2t = pywt.threshold(cD2m, univ, mode=\"hard\")\n",
    "    # compute IPA\n",
    "    ctr = 0\n",
    "    for i in range(len(cD2t )):\n",
    "        if math.fabs(cD2t[i]) > 0: ctr += 1\n",
    "    IPA = float(ctr)/tt.total_seconds()\n",
    "\n",
    "    return IPA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistical Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iqr_outlier_indices(data):\n",
    "    q1 = data.quantile(.25)\n",
    "    q3 = data.quantile(.75)\n",
    "    iqr = stats.iqr(data, nan_policy='omit', rng=(25, 75))\n",
    "    return np.where((data < (q1 - 1.5 * iqr)) | (data > (q3 + 1.5 * iqr)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iqr_stats(data):\n",
    "    q1 = np.percentile(data, 25)\n",
    "    q3 = np.percentile(data, 75)\n",
    "    iqr = stats.iqr(data, nan_policy='omit', rng=(25, 75))\n",
    "    return iqr, q1, q3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_data(file):\n",
    "    streams, header = pyxdf.load_xdf(file)\n",
    "    dfs = {}\n",
    "    for stream in streams:\n",
    "        stream_name = stream['info']['name'][0]\n",
    "        stream_channels = {channel['label'][0]: i for i, channel in enumerate(stream['info']['desc'][0]['channels'][0]['channel'])}\n",
    "        stream_data = stream['time_series']\n",
    "        data_dict = {key: np.array(stream_data)[:, index] for key, index in stream_channels.items()}\n",
    "        data_dict['time'] = np.round(np.array(stream['time_stamps']), decimals=4)\n",
    "        dfs[stream_name] = pd.DataFrame(data_dict).drop_duplicates(subset=['time']).reset_index(drop=True)\n",
    "    return dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "accom_time = pd.to_timedelta(0.5, unit='s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "method_cats = CategoricalDtype(['4DoF','6DoF', 'unimanual','bimanual'], ordered=False)\n",
    "model_cats = CategoricalDtype(['A', 'B', 'C', 'D'], ordered=True)\n",
    "block_cats = CategoricalDtype(['0', '1', '2', '3'], ordered=True)\n",
    "event_cats = CategoricalDtype(['Start', 'PointPlaced', 'Move', 'End', 'Draw', 'Erase', 'PointDeleted'], ordered=False)\n",
    "target_cats = CategoricalDtype(['1','2'], ordered=False)\n",
    "trial_cats = CategoricalDtype(['0','1','2','3'], ordered=True)\n",
    "task_trial_cats = CategoricalDtype(['0','1','2','3', '4', '5', '6', '7'], ordered=True)\n",
    "ssq_cats = CategoricalDtype(['None', 'Slight', 'Moderate', 'Severe'], ordered=True)\n",
    "\n",
    "data_names = ['id', 'block', 'model', 'method']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "mA = [0,1,3,2]\n",
    "mB = [1,2,0,3]\n",
    "mC = [2,3,1,0]\n",
    "mD = [3,0,2,1]\n",
    "\n",
    "tA = [0,1,2,3]\n",
    "tB = [0,1,3,2]\n",
    "tC = [1,0,2,3]\n",
    "tD = [1,0,3,2]\n",
    "\n",
    "model_blocks = [\n",
    "    [mA,mB,mC,mD],\n",
    "    [mB,mC,mD,mA],\n",
    "    [mC,mD,mA,mB],\n",
    "    [mD,mA,mB,mC]\n",
    "]\n",
    "\n",
    "method_blocks = [\n",
    "    tA, tB, tC, tD\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_stream(stream_df, block, range_frame):\n",
    "    df = pd.DataFrame()\n",
    "\n",
    "    for col in stream_df.columns:\n",
    "        df[col] = stream_df[col]\n",
    "    \n",
    "    stream_df['ModelID'] = stream_df['ModelID'].mask(stream_df['ModelID'] == 'generic', '99')\n",
    "    stream_df['MethodID'] = stream_df['MethodID'].mask(stream_df['MethodID'] == 'generic', '99')\n",
    "    df['ModelID'] = stream_df['ModelID'].astype(int)\n",
    "    df['trial_id'] = stream_df['ModelID'].astype(int)\n",
    "    df['MethodID'] = stream_df['MethodID'].astype(int)\n",
    "    df['task_trial_id'] = df['trial_id']\n",
    "    df['task_trial_id'] = df['task_trial_id'].mask(df['task_trial_id'] == 4, 99)\n",
    "\n",
    "    for j in range_frame:\n",
    "        m = 0 if j == range_frame[0] else 4\n",
    "        for i in range(4):\n",
    "            method = method_blocks[block][j]\n",
    "            current_trial_id = df.loc[(df['trial_id']==i) & (df['MethodID']==method), 'trial_id']\n",
    "            df['ModelID'] = df['ModelID'].mask((df['trial_id']==i) & (df['MethodID']==method), model_blocks[block][j][i])\n",
    "            df.loc[(df['trial_id']==i) & (df['MethodID']==method), 'task_trial_id'] = m + current_trial_id\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_gaze_luminance_data(stream_df):\n",
    "    pupil = stream_df['GazeStream'].loc[(stream_df['GazeStream']['LeftEyeIsBlinking'] == 0) \n",
    "                                        & (stream_df['GazeStream']['RightEyeIsBlinking'] == 0) \n",
    "                                        & (stream_df['GazeStream']['LeftPupilDiameter'] > 0) \n",
    "                                        & (stream_df['GazeStream']['RightPupilDiameter'] > 0), \n",
    "                                        ['time', 'trial_id', 'task_trial_id', 'MethodID', 'ModelID', 'LeftPupilDiameter', 'RightPupilDiameter']]\n",
    "    pupil['time'] = pd.to_timedelta(pupil['time'], unit='s')\n",
    "\n",
    "    lum = stream_df['LuminanceStream'].loc[:, ['time', 'MethodID', 'ModelID', 'Luminance']]\n",
    "    lum['time'] = pd.to_timedelta(lum['time'], unit='s')\n",
    "\n",
    "    # Intersection of time stamps\n",
    "    pupil_lum_time_intersection = np.intersect1d(pupil['time'], lum['time'])\n",
    "\n",
    "    # Filter pupil and luminance data by intersection\n",
    "    pupil = pupil[pupil['time'].isin(pupil_lum_time_intersection)].reset_index(drop=True)\n",
    "    lum = lum[lum['time'].isin(pupil_lum_time_intersection)].reset_index(drop=True)\n",
    "\n",
    "    # Combined DataFrame for pupil and luminance\n",
    "    pupil_lum = pd.DataFrame({\n",
    "        'time': pd.to_timedelta(pupil_lum_time_intersection, unit='s'),\n",
    "        'luminance': lum['Luminance'],\n",
    "        'pupilDiameter': 0.5 * (pupil['LeftPupilDiameter'] + pupil['RightPupilDiameter']),\n",
    "        'methodID': pupil['MethodID'],\n",
    "        'modelID': pupil['ModelID'],\n",
    "        'trial_id': pupil['trial_id'],\n",
    "        'task_trial_id': pupil['task_trial_id']\n",
    "    })\n",
    "\n",
    "    outliers = iqr_outlier_indices(pupil_lum['pupilDiameter'])\n",
    "    pupil_lum = pupil_lum.drop(pupil_lum.iloc[outliers].index).reset_index(drop=True)\n",
    "\n",
    "    return pupil_lum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_calibration_data(pupil_lum_df, stream_df):\n",
    "    calibration_events = stream_df['ExperimentStream'].loc[(stream_df['ExperimentStream']['EventType'] == 'CalibrationColorChange') | \n",
    "                                                           (stream_df['ExperimentStream']['SceneEvent'] == 'Calibration') | \n",
    "                                                           (stream_df['ExperimentStream']['SceneEvent'] == 'CalibrationComplete'), \n",
    "                                                           ['time','SceneEvent', 'EventType']]\n",
    "    calibration_events['time'] = pd.to_timedelta(calibration_events['time'], unit='s')\n",
    "    c_start_times = calibration_events[:8]['time']\n",
    "    c_end_times = calibration_events[1:]['time']\n",
    "    c_start_times.reset_index(drop=True, inplace=True)\n",
    "    c_end_times.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    calib_data = {}\n",
    "    for i in range(8):\n",
    "        calib_data[i] = pupil_lum_df.loc[(pupil_lum_df['time'] >= c_start_times[i]) & (pupil_lum_df['time'] <= c_end_times[i]), ['time','luminance', 'pupilDiameter']]\n",
    "        calib_data[i]['time'] -= calib_data[i]['time'].iloc[0]\n",
    "        calib_data[i] = calib_data[i].loc[(calib_data[i]['time'] >= accom_time), ['luminance', 'pupilDiameter']]\n",
    "\n",
    "    calibration_data = pd.concat(calib_data).groupby(level=0).mean().sort_values(by=['luminance']).reset_index(drop=True)\n",
    "    return calibration_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_navigation_data(pupil_lum_df, stream_df, a, b, c):\n",
    "    grouped_data = stream_df['NavigationStream'].groupby(['ModelID', 'MethodID'])\n",
    "\n",
    "    stream_df['SurveyStream']['ModelID'] = stream_df['SurveyStream']['ModelID'].astype(float)\n",
    "    stream_df['SurveyStream']['MethodID'] = stream_df['SurveyStream']['MethodID'].astype(float)\n",
    "    \n",
    "    discomfort_survey = stream_df['SurveyStream'].loc[\n",
    "        (stream_df['SurveyStream']['SurveyType'] == 'Discomfort') & \n",
    "        (stream_df['SurveyStream']['ModelID'] < 4), \n",
    "        ['time', 'ModelID', 'MethodID']]\n",
    "    survey_group = discomfort_survey.groupby(['ModelID', 'MethodID'])\n",
    "\n",
    "    start_times = []\n",
    "    end_times = []\n",
    "    total_time = []\n",
    "\n",
    "    for i in range(4):\n",
    "        for j in range(2,4):\n",
    "            trial = grouped_data.get_group((i, j))\n",
    "\n",
    "            start = trial.loc[(trial['spline_percent'] > 0.001)].index[0]\n",
    "            start_time = pd.to_timedelta(stream_df['NavigationStream'].loc[start, 'time'], unit='s')\n",
    "\n",
    "            end = trial.loc[(trial['spline_percent'] > 0.995)]\n",
    "            end_time = 0\n",
    "            # For 6DoF navigation, completion was determined by collision with bounding box\n",
    "            # Spline percentage was based on projection, so it may not reach > 0.995.\n",
    "            # In this case, the survey time serves as the end time (rather than lowering the threshold)\n",
    "            if len(end) > 0:\n",
    "                end = end.index[0]\n",
    "                end_time = pd.to_timedelta(stream_df['NavigationStream'].loc[end, 'time'], unit='s')\n",
    "            else:\n",
    "                end = survey_group.get_group((i, j)).index[0]\n",
    "                end_time = pd.to_timedelta(stream_df['SurveyStream'].loc[end, 'time'], unit='s') - pd.offsets.Second(3)\n",
    "            \n",
    "            start_times.append(start_time)\n",
    "            end_times.append(end_time)\n",
    "            total_time.append((end_time - start_time).total_seconds())\n",
    "\n",
    "\n",
    "    nav_start_times = start_times\n",
    "    nav_end_times = end_times\n",
    "\n",
    "    nav_data = {}\n",
    "    for i in range(8):\n",
    "        nav_data[i] = pupil_lum_df.loc[\n",
    "            (pupil_lum_df['luminance'] >0) & \n",
    "            (pupil_lum_df['time']>nav_start_times[i]) & \n",
    "            (pupil_lum_df['time']<nav_end_times[i]), \n",
    "            ['time', 'trial_id', 'task_trial_id', 'methodID', 'modelID', 'luminance', 'pupilDiameter']]\n",
    "        nav_data[i].reset_index(drop=True, inplace=True)\n",
    "\n",
    "    navigation_data = pd.concat(nav_data, names=['trial'])\n",
    "    navigation_data['pupil_lum_base'] = pupil_func(navigation_data['luminance'], a, b, c)\n",
    "    navigation_data['adj_pupil'] = navigation_data['pupilDiameter'] - navigation_data['pupil_lum_base']\n",
    "\n",
    "    return navigation_data, total_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_creation_data(pupil_lum_df, stream_df, a, b, c):\n",
    "    \n",
    "    crt_start_times = stream_df['CreationStream'].loc[\n",
    "    (stream_df['CreationStream']['EventName'] == 'StartPointRegistered'), ['time', 'ModelID', 'MethodID']]\n",
    "    crt_start_times = pd.to_timedelta(crt_start_times.groupby(['ModelID', 'MethodID']).first()['time'], unit='s') + pd.offsets.Second(2)\n",
    "    crt_start_times.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    crt_end_times = stream_df['CreationStream'].loc[(stream_df['CreationStream']['EventName'] == 'FinishPath'), ['time', 'ModelID', 'MethodID']]\n",
    "    crt_end_times = pd.to_timedelta(crt_end_times.groupby(['ModelID', 'MethodID']).first()['time'], unit='s')\n",
    "    crt_end_times.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    total_time = crt_end_times - crt_start_times\n",
    "    total_time = total_time.apply(lambda x: x.total_seconds())\n",
    "\n",
    "    crt_data = {}\n",
    "    for i in range(8):\n",
    "        crt_data[i] = pupil_lum_df.loc[\n",
    "            (pupil_lum_df['time'] > crt_start_times.loc[i]) & \n",
    "            (pupil_lum_df['time'] < crt_end_times.loc[i]), \n",
    "            ['time', 'methodID', 'modelID', 'trial_id',  'task_trial_id', 'luminance', 'pupilDiameter']]\n",
    "        crt_data[i].reset_index(drop=True, inplace=True)\n",
    "\n",
    "    creation_data = pd.concat(crt_data, names=['trial'])\n",
    "    creation_data['pupil_lum_base'] = pupil_func(creation_data['luminance'], a, b, c)\n",
    "    creation_data['adj_pupil'] = creation_data['pupilDiameter'] - creation_data['pupil_lum_base']\n",
    "    \n",
    "    return creation_data, total_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_creation_stats(stream_df):\n",
    "    \n",
    "    group = stream_df['CreationStream'].groupby(['ModelID', 'MethodID'])\n",
    "    creation_counts  = []\n",
    "\n",
    "    for i in range(4):\n",
    "            for j in range(0,2):\n",
    "                trial = group.get_group((i,j))\n",
    "                creation_counts.append(trial.groupby('EventType', observed=False).size().fillna(0))\n",
    "    \n",
    "    keys = [(i,j) for i in range(4) for j in range(0,2)]\n",
    "    creation_stats = pd.concat(creation_counts, axis=0, keys=keys, names=['ModelID', 'MethodID']).unstack(level=2)\n",
    "    creation_stats = creation_stats.drop(columns=['End', 'Start'])\n",
    "    return creation_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_target_trial_data_crt(stream_df):\n",
    "    target_set = stream_df['ExperimentStream'].loc[\n",
    "        (stream_df['ExperimentStream']['EventType'] == 'TargetPointsSet') | \n",
    "        (stream_df['ExperimentStream']['EventType'] == 'SceneLoaded') & \n",
    "        (stream_df['ExperimentStream']['SceneEvent'] != 'Calibration') & \n",
    "        (stream_df['ExperimentStream']['MethodID'] != 2) & \n",
    "        (stream_df['ExperimentStream']['MethodID'] != 3), ['SceneEvent', 'EventType', 'ModelID', 'MethodID']]\n",
    "\n",
    "    generic_idx = np.where(target_set['ModelID'] == 99)[0]\n",
    "    idx = [x+1 for x in generic_idx]\n",
    "\n",
    "    for i in range(len(generic_idx)):\n",
    "        target_set.loc[target_set.index[generic_idx[i]], 'ModelID']  = target_set.loc[target_set.index[idx[i]], 'ModelID']\n",
    "        target_set.loc[target_set.index[generic_idx[i]], 'MethodID']  = target_set.loc[target_set.index[idx[i]], 'MethodID']\n",
    "\n",
    "    target_set = target_set.loc[(target_set['ModelID'] < 4) & (target_set['EventType'] == 'TargetPointsSet'), ['SceneEvent', 'ModelID', 'MethodID']]\n",
    "\n",
    "    target_set['SceneEvent'] = target_set.mask(target_set['SceneEvent'] == 'TargetsLoaded_Set1', target_cats.categories[0])['SceneEvent']\n",
    "    target_set['SceneEvent'] = target_set.mask(target_set['SceneEvent'] == 'TargetsLoaded_Set2', target_cats.categories[1])['SceneEvent']\n",
    "\n",
    "    target_set['targetID'] = target_set['SceneEvent']\n",
    "    target_set.drop(columns=['SceneEvent'], inplace=True)\n",
    "\n",
    "    return target_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_target_trial_data_nav(stream_df, target_set_group):\n",
    "    target_set = stream_df['NavigationStream'].loc[(stream_df['NavigationStream']['ModelID'] < 4), ['model_source', 'ModelID', 'MethodID']]\n",
    "\n",
    "    groups = target_set.groupby(['ModelID', 'MethodID'])\n",
    "\n",
    "    target_set['creation_method'] = '-1'\n",
    "    target_set['target_set_source'] = '-1'\n",
    "\n",
    "    target_trials = []\n",
    "\n",
    "    for i in range(4):\n",
    "        for j in range(2,4):\n",
    "            trial = groups.get_group((i, j))\n",
    "            model_source = trial['model_source'].iloc[0]\n",
    "            model_value16 = model_source - 16\n",
    "            method = '-1'\n",
    "            method_id = -1\n",
    "\n",
    "            if model_value16 > 9:\n",
    "                method = 'bimanual'\n",
    "                method_id = 1\n",
    "            else:\n",
    "                method = 'unimanual'\n",
    "                method_id = 0\n",
    "\n",
    "            trial.loc[:, 'creation_method'] = method\n",
    "\n",
    "            model_i = trial['ModelID'].iloc[0]\n",
    "            group = target_set_group.get_group((int(model_i),int(method_id)))\n",
    "\n",
    "            target = group['targetID'].iloc[0]\n",
    "            trial.loc[:, 'target_set_source'] = target\n",
    "            target_trials.append(trial.iloc[:1])\n",
    "\n",
    "    target_set = pd.concat(target_trials)\n",
    "\n",
    "    target_set['creation_method'] = target_set['creation_method'].astype('string').astype(method_cats)\n",
    "    target_set['target_set_source'] = target_set['target_set_source'].astype('string').astype(target_cats)\n",
    "    target_set.drop(columns=['model_source'], inplace=True)\n",
    "    target_set.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    return target_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_discomfort_data(stream_df) -> pd.DataFrame:\n",
    "    discomfort_values = stream_df['SurveyStream'].loc[stream_df['SurveyStream']['SurveyType'] == 'Discomfort', ['time', 'Value', 'ModelID', 'MethodID']]\n",
    "    discomfort_values['time'] = pd.to_timedelta(discomfort_values['time'], unit='s')\n",
    "    discomfort_values.reset_index(drop=True, inplace=True)\n",
    "    return discomfort_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_seq_data(stream_df) -> pd.DataFrame:\n",
    "    seq_values = stream_df['SurveyStream'].loc[stream_df['SurveyStream']['SurveyType'] == 'SEQ', ['time', 'Value', 'ModelID', 'MethodID']]\n",
    "    seq_values['time'] = pd.to_timedelta(seq_values['time'], unit='s')\n",
    "    seq_values.reset_index(drop=True, inplace=True)\n",
    "    return seq_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_ipa_calc(data):\n",
    "    methods = []\n",
    "    models = []\n",
    "    ipa = []\n",
    "    for i in range(8):\n",
    "        methods.append(data.loc[i]['methodID'].iloc[i])\n",
    "        models.append(data.loc[i]['modelID'].iloc[i])\n",
    "        pupil = data.loc[i]['pupilDiameter']\n",
    "        pupil.index = data.loc[i]['time']\n",
    "        ipa.append(ipa_func(pupil))\n",
    "        \n",
    "    return pd.DataFrame({'methodID': methods, 'modelID': models, 'IPA': ipa})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = join(getcwd(),'Path_Data')\n",
    "data_files = [join(data_dir, f) for f in listdir(data_dir) if isfile(join(data_dir, f))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m dfs \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m data_files:\n\u001b[1;32m----> 3\u001b[0m     df \u001b[38;5;241m=\u001b[39m import_data(file)\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;66;03m#'LuminanceStream', 'GazeStream', 'NavigationStream', 'CreationStream', 'PoseStream', 'ExperimentStream', 'SurveyStream', 'TrackedPoseStream'\u001b[39;00m\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;66;03m# Remove final empty row from string data streams\u001b[39;00m\n\u001b[0;32m      6\u001b[0m     df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSurveyStream\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSurveyStream\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m^\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124ms*$\u001b[39m\u001b[38;5;124m'\u001b[39m, np\u001b[38;5;241m.\u001b[39mnan, regex\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\u001b[38;5;241m.\u001b[39mdropna()\n",
      "Cell \u001b[1;32mIn[7], line 2\u001b[0m, in \u001b[0;36mimport_data\u001b[1;34m(file)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mimport_data\u001b[39m(file):\n\u001b[1;32m----> 2\u001b[0m     streams, header \u001b[38;5;241m=\u001b[39m pyxdf\u001b[38;5;241m.\u001b[39mload_xdf(file)\n\u001b[0;32m      3\u001b[0m     dfs \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m stream \u001b[38;5;129;01min\u001b[39;00m streams:\n",
      "File \u001b[1;32mc:\\Users\\court\\anaconda3\\envs\\path_data\\Lib\\site-packages\\pyxdf\\pyxdf.py:364\u001b[0m, in \u001b[0;36mload_xdf\u001b[1;34m(filename, select_streams, on_chunk, synchronize_clocks, handle_clock_resets, dejitter_timestamps, jitter_break_threshold_seconds, jitter_break_threshold_samples, clock_reset_threshold_seconds, clock_reset_threshold_stds, clock_reset_threshold_offset_seconds, clock_reset_threshold_offset_stds, winsor_threshold, verbose)\u001b[0m\n\u001b[0;32m    362\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m synchronize_clocks:\n\u001b[0;32m    363\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  performing clock synchronization...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 364\u001b[0m     temp \u001b[38;5;241m=\u001b[39m _clock_sync(\n\u001b[0;32m    365\u001b[0m         temp,\n\u001b[0;32m    366\u001b[0m         handle_clock_resets,\n\u001b[0;32m    367\u001b[0m         clock_reset_threshold_stds,\n\u001b[0;32m    368\u001b[0m         clock_reset_threshold_seconds,\n\u001b[0;32m    369\u001b[0m         clock_reset_threshold_offset_stds,\n\u001b[0;32m    370\u001b[0m         clock_reset_threshold_offset_seconds,\n\u001b[0;32m    371\u001b[0m         winsor_threshold,\n\u001b[0;32m    372\u001b[0m     )\n\u001b[0;32m    374\u001b[0m \u001b[38;5;66;03m# perform jitter removal if requested\u001b[39;00m\n\u001b[0;32m    375\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dejitter_timestamps:\n",
      "File \u001b[1;32mc:\\Users\\court\\anaconda3\\envs\\path_data\\Lib\\site-packages\\pyxdf\\pyxdf.py:625\u001b[0m, in \u001b[0;36m_clock_sync\u001b[1;34m(streams, handle_clock_resets, reset_threshold_stds, reset_threshold_seconds, reset_threshold_offset_stds, reset_threshold_offset_seconds, winsor_threshold)\u001b[0m\n\u001b[0;32m    623\u001b[0m y \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(clock_values[start:stop]) \u001b[38;5;241m/\u001b[39m winsor_threshold\n\u001b[0;32m    624\u001b[0m \u001b[38;5;66;03m# noinspection PyTypeChecker\u001b[39;00m\n\u001b[1;32m--> 625\u001b[0m _coefs \u001b[38;5;241m=\u001b[39m _robust_fit(X, y)\n\u001b[0;32m    626\u001b[0m _coefs[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m winsor_threshold\n\u001b[0;32m    627\u001b[0m coef\u001b[38;5;241m.\u001b[39mappend(_coefs)\n",
      "File \u001b[1;32mc:\\Users\\court\\anaconda3\\envs\\path_data\\Lib\\site-packages\\pyxdf\\pyxdf.py:725\u001b[0m, in \u001b[0;36m_robust_fit\u001b[1;34m(A, y, rho, iters)\u001b[0m\n\u001b[0;32m    723\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(iters):\n\u001b[0;32m    724\u001b[0m     x \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39msolve(U, (np\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39msolve(L, Aty \u001b[38;5;241m+\u001b[39m np\u001b[38;5;241m.\u001b[39mdot(A\u001b[38;5;241m.\u001b[39mT, z \u001b[38;5;241m-\u001b[39m u))))\n\u001b[1;32m--> 725\u001b[0m     d \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdot(A, x) \u001b[38;5;241m-\u001b[39m y \u001b[38;5;241m+\u001b[39m u\n\u001b[0;32m    726\u001b[0m     d_inv \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdivide(\u001b[38;5;241m1\u001b[39m, d, where\u001b[38;5;241m=\u001b[39md \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m    727\u001b[0m     tmp \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmaximum(\u001b[38;5;241m0\u001b[39m, (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m/\u001b[39m rho) \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39mabs(d_inv)))\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "dfs = []\n",
    "for file in data_files:\n",
    "    df = import_data(file)\n",
    "    #'LuminanceStream', 'GazeStream', 'NavigationStream', 'CreationStream', 'PoseStream', 'ExperimentStream', 'SurveyStream', 'TrackedPoseStream'\n",
    "    # Remove final empty row from string data streams\n",
    "    df['SurveyStream'] = df['SurveyStream'].replace(r'^\\s*$', np.nan, regex=True).dropna()\n",
    "    df['CreationStream'] = df['CreationStream'].replace(r'^\\s*$', np.nan, regex=True).dropna()\n",
    "    df['ExperimentStream'] = df['ExperimentStream'].replace(r'^\\s*$', np.nan, regex=True).dropna()\n",
    "\n",
    "    df['SurveyStream']['ModelID'] = df['SurveyStream']['ModelID'].astype(float)\n",
    "    df['SurveyStream']['MethodID'] = df['SurveyStream']['MethodID'].astype(float)\n",
    "    df['SurveyStream']['Value'] = df['SurveyStream']['Value'].astype(float)\n",
    "\n",
    "    df['CreationStream']['ModelID'] = df['CreationStream']['ModelID'].astype(float)\n",
    "    df['CreationStream']['MethodID'] = df['CreationStream']['MethodID'].astype(float)\n",
    "    df['CreationStream']['EventType'] = df['CreationStream']['EventType'].astype(event_cats)\n",
    "\n",
    "    block = int(df['ExperimentStream']['BlockID'][0])\n",
    "    df['GazeStream'] = clean_stream(df['GazeStream'], block, range(4))\n",
    "    df['LuminanceStream'] = clean_stream(df['LuminanceStream'], block, range(4))\n",
    "    df['NavigationStream'] = clean_stream(df['NavigationStream'], block, range(2,4))\n",
    "    df['CreationStream'] = clean_stream(df['CreationStream'], block, range(2))\n",
    "    df['PoseStream'] = clean_stream(df['PoseStream'], block, range(4))\n",
    "    df['SurveyStream'] = clean_stream(df['SurveyStream'], block, range(4))\n",
    "    df['TrackedPoseStream'] = clean_stream(df['TrackedPoseStream'], block, range(4))\n",
    "    df['ExperimentStream'] = clean_stream(df['ExperimentStream'], block, range(4))\n",
    "    dfs.append(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_dfs_nav = []\n",
    "user_dfs_crt = []\n",
    "ids = []\n",
    "blocks = []\n",
    "\n",
    "for df in dfs:\n",
    "    id = df['ExperimentStream']['UserID'][0]\n",
    "    block = df['ExperimentStream']['BlockID'][0]\n",
    "    ids.append(id)\n",
    "    blocks.append(block)\n",
    "\n",
    "    pupil_lum_df = process_gaze_luminance_data(df)\n",
    "    calibration_data = process_calibration_data(pupil_lum_df, df)\n",
    "\n",
    "    # Fit pupil response to luminance\n",
    "    x_data = calibration_data['luminance']\n",
    "    y_data = calibration_data['pupilDiameter']\n",
    "    exp_mod = Model(pupil_func)\n",
    "    params = exp_mod.make_params(a=1, b=4, c=0)\n",
    "    result = exp_mod.fit(y_data, params, x=x_data)\n",
    "    a = result.params['a'].value\n",
    "    b = result.params['b'].value\n",
    "    c = result.params['c'].value\n",
    "\n",
    "    navigation_data, nav_time = process_navigation_data(pupil_lum_df, df, a, b, c)\n",
    "    ipa_calc_nav = process_ipa_calc(navigation_data)\n",
    "    creation_data, crt_time = process_creation_data(pupil_lum_df, df, a, b, c)\n",
    "    ipa_calc_crt = process_ipa_calc(creation_data)\n",
    "    creation_stats = process_creation_stats(df)\n",
    "    discomfort = process_discomfort_data(df)\n",
    "    seq = process_seq_data(df)\n",
    "\n",
    "    creation_target_trials = process_target_trial_data_crt(df)\n",
    "    crt_target_trials = creation_target_trials.groupby(['ModelID', 'MethodID'])\n",
    "    navigation_target_trials = process_target_trial_data_nav(df, crt_target_trials)\n",
    "    nav_target_trials = navigation_target_trials.groupby(['ModelID', 'MethodID'])\n",
    "\n",
    "    nav_trials = navigation_data.groupby(['modelID', 'methodID'])\n",
    "    ipa_nav_trials = ipa_calc_nav.groupby(['modelID', 'methodID'])\n",
    "    crt_trials = creation_data.groupby(['modelID', 'methodID'])\n",
    "    ipa_crt_trials = ipa_calc_crt.groupby(['modelID', 'methodID'])\n",
    "    discomfort_trials = discomfort.groupby(['ModelID', 'MethodID'])\n",
    "    seq_trials = seq.groupby(['ModelID', 'MethodID'])\n",
    "\n",
    "    nav_data = {}\n",
    "    nav_total_time = {}\n",
    "    ipa_nav_data = {}\n",
    "    crt_data = {}\n",
    "    crt_total_time = {}\n",
    "    ipa_crt_data = {}\n",
    "    discomfort_data = {}\n",
    "    seq_crt = {}\n",
    "    seq_nav = {}\n",
    "    target_data_crt = {}\n",
    "    target_data_nav = {}\n",
    "    creation_data_nav = {}\n",
    "\n",
    "    for i in range(4):\n",
    "        for j in range(2,4):\n",
    "            nav_data[(id, block, i, j)] = nav_trials.get_group((i,j)).mean()\n",
    "            nav_total_time[(id, block, i, j)] = nav_time[(2*i + (j-2))]\n",
    "            ipa_nav_data[(id, block, i, j)] = ipa_nav_trials.get_group((i,j)).mean()\n",
    "            discomfort_data[(id, block, i, j)] = discomfort_trials.get_group((i,j)).mean()\n",
    "            seq_nav[(id, block, i, j)] = seq_trials.get_group((i,j)).mean()\n",
    "            target_data_nav[(id, block, i, j)] = nav_target_trials.get_group((i,j))['target_set_source'].iloc[0]\n",
    "            creation_data_nav[(id, block, i, j)] = nav_target_trials.get_group((i,j))['creation_method'].iloc[0]\n",
    "    \n",
    "    for i in range(4):\n",
    "        for j in range(0,2):\n",
    "            crt_data[(id, block, i, j)] = crt_trials.get_group((i,j)).mean()\n",
    "            crt_total_time[(id, block, i, j)] = crt_time[(2*i + j)]\n",
    "            ipa_crt_data[(id, block, i, j)] = ipa_crt_trials.get_group((i,j)).mean()\n",
    "            seq_crt[(id, block, i, j)] = seq_trials.get_group((i,j)).mean()\n",
    "            target_data_crt[(id, block, i, j)] = crt_target_trials.get_group((i,j))['targetID'].iloc[0]\n",
    "    \n",
    "    nav_index = pd.MultiIndex.from_product([[id], [block], model_cats.categories, method_cats.categories[0:2]], names=data_names)\n",
    "    crt_index = pd.MultiIndex.from_product([[id], [block], model_cats.categories, method_cats.categories[2:4]], names=data_names)\n",
    "\n",
    "    nav_data = pd.concat(nav_data, axis=1, names=data_names).T\n",
    "    nav_data['total_time'] = nav_total_time\n",
    "    nav_data['target_source'] = target_data_nav\n",
    "    nav_data['creation_method'] = creation_data_nav\n",
    "    nav_data.index = nav_index\n",
    "    nav_data.drop(columns=['time', 'modelID', 'methodID'], inplace=True)\n",
    "    \n",
    "    crt_data = pd.concat(crt_data, axis=1, names=data_names).T\n",
    "    crt_data['total_time'] = crt_total_time\n",
    "    crt_data['target_id'] = target_data_crt\n",
    "    crt_data.index = crt_index\n",
    "    crt_data.drop(columns=['time', 'modelID', 'methodID'], inplace=True)\n",
    "\n",
    "    creation_stats.index = crt_index\n",
    "\n",
    "    ipa_nav_data = pd.concat(ipa_nav_data, axis=1, names=data_names).T\n",
    "    ipa_nav_data.index = nav_index\n",
    "    ipa_nav_data.drop(columns=['modelID', 'methodID'], inplace=True)\n",
    "\n",
    "    ipa_crt_data = pd.concat(ipa_crt_data, axis=1, names=data_names).T\n",
    "    ipa_crt_data.index = crt_index\n",
    "    ipa_crt_data.drop(columns=['modelID', 'methodID'], inplace=True)\n",
    "\n",
    "    discomfort_data = pd.concat(discomfort_data, axis=1, names=data_names).T\n",
    "    discomfort_data.index = nav_index\n",
    "    discomfort_data['discomfort'] = discomfort_data['Value']\n",
    "    discomfort_data.drop(columns=['time', 'ModelID', 'MethodID', 'Value'], inplace=True)\n",
    "\n",
    "    seq_nav = pd.concat(seq_nav, axis=1, names=data_names).T\n",
    "    seq_nav.index = nav_index\n",
    "    seq_nav['seq'] = seq_nav['Value']\n",
    "    seq_nav.drop(columns=['time', 'ModelID', 'MethodID', 'Value'], inplace=True)\n",
    "\n",
    "    seq_crt = pd.concat(seq_crt, axis=1, names=data_names).T\n",
    "    seq_crt.index = crt_index\n",
    "    seq_crt['seq'] = seq_crt['Value']\n",
    "    seq_crt.drop(columns=['time', 'ModelID', 'MethodID', 'Value'], inplace=True)\n",
    "\n",
    "    df_crt = pd.concat([crt_data, ipa_crt_data, seq_crt, creation_stats], axis=0).stack().unstack()\n",
    "    df_crt.loc[(slice(None), slice(None), slice(None), slice(None)), ('Draw', 'Erase', 'PointPlaced', 'Move', 'PointDeleted')] = df_crt.loc[(slice(None), slice(None), slice(None), slice(None)), ('Draw', 'Erase', 'PointPlaced', 'Move', 'PointDeleted')].astype(int)\n",
    "    df_crt.loc[(slice(None), slice(None), slice(None), 'unimanual'), ('Draw', 'Erase')] = df_crt.loc[(slice(None), slice(None), slice(None), 'unimanual'), ('Draw', 'Erase')].astype(int).fillna(0)\n",
    "    df_crt.loc[(slice(None), slice(None), slice(None), 'bimanual'), ('PointPlaced', 'Move', 'PointDeleted')] = df_crt.loc[(slice(None), slice(None), slice(None), 'bimanual'), ('PointPlaced', 'Move', 'PointDeleted')].astype(int).fillna(0)\n",
    "\n",
    "    df_nav = pd.concat([nav_data, ipa_nav_data, discomfort_data, seq_nav], axis=0).stack().unstack()\n",
    "\n",
    "    user_dfs_nav.append(df_nav)\n",
    "    user_dfs_crt.append(df_crt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_data_nav = pd.concat(user_dfs_nav)\n",
    "nav_dtype = {'luminance': 'float64', 'pupilDiameter': 'float64', 'pupil_lum_base': 'float64', 'adj_pupil': 'float64', 'IPA': 'float64', 'discomfort': 'int32', 'seq': 'int32', 'total_time': 'float64'}\n",
    "user_data_nav = user_data_nav.astype(nav_dtype)\n",
    "\n",
    "short_nav = user_data_nav['total_time'] < 10\n",
    "user_data_nav = user_data_nav[~short_nav]\n",
    "\n",
    "user_data_crt = pd.concat(user_dfs_crt)\n",
    "crt_dtype = {'luminance' : 'float64', 'pupilDiameter' : 'float64', 'pupil_lum_base' : 'float64', 'adj_pupil' : 'float64', 'IPA' : 'float64', 'seq' : 'int32', 'PointPlaced' : 'int32', 'Move' : 'int32', 'Draw' : 'int32', 'Erase' : 'int32', 'PointDeleted' : 'int32', 'total_time': 'float64'}\n",
    "user_data_crt = user_data_crt.astype(crt_dtype)\n",
    "\n",
    "short_crt = user_data_crt['total_time'] < 10\n",
    "user_data_crt = user_data_crt[~short_crt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_data_nav.to_pickle('user_data_nav.pkl')\n",
    "user_data_crt.to_pickle('user_data_crt.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_csv = pd.read_csv('pre_study.csv', keep_default_na = False, na_values = [''])\n",
    "post_csv = pd.read_csv('post_study.csv', keep_default_na = False, na_values = [''])\n",
    "\n",
    "pre_csv['Q3_1'] = pre_csv['Q3_1'].astype(ssq_cats).cat.codes\n",
    "pre_csv['Q3_2'] = pre_csv['Q3_2'].astype(ssq_cats).cat.codes\n",
    "pre_csv['Q3_3'] = pre_csv['Q3_3'].astype(ssq_cats).cat.codes\n",
    "pre_csv['Q3_4'] = pre_csv['Q3_4'].astype(ssq_cats).cat.codes\n",
    "pre_csv['Q3_5'] = pre_csv['Q3_5'].astype(ssq_cats).cat.codes\n",
    "pre_csv['Q3_6'] = pre_csv['Q3_6'].astype(ssq_cats).cat.codes\n",
    "pre_csv['Q3_7'] = pre_csv['Q3_7'].astype(ssq_cats).cat.codes\n",
    "pre_csv['Q3_8'] = pre_csv['Q3_8'].astype(ssq_cats).cat.codes\n",
    "pre_csv['Q3_9'] = pre_csv['Q3_9'].astype(ssq_cats).cat.codes\n",
    "pre_csv['Q3_10'] = pre_csv['Q3_10'].astype(ssq_cats).cat.codes\n",
    "pre_csv['Q3_11'] = pre_csv['Q3_11'].astype(ssq_cats).cat.codes\n",
    "pre_csv['Q3_12'] = pre_csv['Q3_12'].astype(ssq_cats).cat.codes\n",
    "pre_csv['Q3_13'] = pre_csv['Q3_13'].astype(ssq_cats).cat.codes\n",
    "pre_csv['Q3_14'] = pre_csv['Q3_14'].astype(ssq_cats).cat.codes\n",
    "pre_csv['Q3_15'] = pre_csv['Q3_15'].astype(ssq_cats).cat.codes\n",
    "pre_csv['Q3_16'] = pre_csv['Q3_16'].astype(ssq_cats).cat.codes\n",
    "\n",
    "post_csv['Q3_1'] = post_csv['Q3_1'].astype(ssq_cats).cat.codes\n",
    "post_csv['Q3_2'] = post_csv['Q3_2'].astype(ssq_cats).cat.codes\n",
    "post_csv['Q3_3'] = post_csv['Q3_3'].astype(ssq_cats).cat.codes\n",
    "post_csv['Q3_4'] = post_csv['Q3_4'].astype(ssq_cats).cat.codes\n",
    "post_csv['Q3_5'] = post_csv['Q3_5'].astype(ssq_cats).cat.codes\n",
    "post_csv['Q3_6'] = post_csv['Q3_6'].astype(ssq_cats).cat.codes\n",
    "post_csv['Q3_7'] = post_csv['Q3_7'].astype(ssq_cats).cat.codes\n",
    "post_csv['Q3_8'] = post_csv['Q3_8'].astype(ssq_cats).cat.codes\n",
    "post_csv['Q3_9'] = post_csv['Q3_9'].astype(ssq_cats).cat.codes\n",
    "post_csv['Q3_10'] = post_csv['Q3_10'].astype(ssq_cats).cat.codes\n",
    "post_csv['Q3_11'] = post_csv['Q3_11'].astype(ssq_cats).cat.codes\n",
    "post_csv['Q3_12'] = post_csv['Q3_12'].astype(ssq_cats).cat.codes\n",
    "post_csv['Q3_13'] = post_csv['Q3_13'].astype(ssq_cats).cat.codes\n",
    "post_csv['Q3_14'] = post_csv['Q3_14'].astype(ssq_cats).cat.codes\n",
    "post_csv['Q3_15'] = post_csv['Q3_15'].astype(ssq_cats).cat.codes\n",
    "post_csv['Q3_16'] = post_csv['Q3_16'].astype(ssq_cats).cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_n_raw = pre_csv['Q3_1'] + pre_csv['Q3_6'] + pre_csv['Q3_7'] + pre_csv['Q3_8'] + pre_csv['Q3_9'] + pre_csv['Q3_15'] + pre_csv['Q3_16']\n",
    "pre_o_raw = pre_csv['Q3_1'] + pre_csv['Q3_2'] + pre_csv['Q3_3'] + pre_csv['Q3_4'] + pre_csv['Q3_5'] + pre_csv['Q3_9'] + pre_csv['Q3_11']\n",
    "pre_d_raw = pre_csv['Q3_5'] + pre_csv['Q3_8'] + pre_csv['Q3_10'] + pre_csv['Q3_11'] + pre_csv['Q3_12'] + pre_csv['Q3_13'] + pre_csv['Q3_14']\n",
    "\n",
    "post_n_raw = post_csv['Q3_1'] + post_csv['Q3_6'] + post_csv['Q3_7'] + post_csv['Q3_8'] + post_csv['Q3_9'] + post_csv['Q3_15'] + post_csv['Q3_16']\n",
    "post_o_raw = post_csv['Q3_1'] + post_csv['Q3_2'] + post_csv['Q3_3'] + post_csv['Q3_4'] + post_csv['Q3_5'] + post_csv['Q3_9'] + post_csv['Q3_11']\n",
    "post_d_raw = post_csv['Q3_5'] + post_csv['Q3_8'] + post_csv['Q3_10'] + post_csv['Q3_11'] + post_csv['Q3_12'] + post_csv['Q3_13'] + post_csv['Q3_14']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "participant_data = pd.DataFrame()\n",
    "participant_data['id'] = post_csv['Q1']\n",
    "participant_data['block'] = post_csv['Q1'] % 4\n",
    "participant_data['age'] = post_csv['Q11']\n",
    "participant_data['sex'] = post_csv['Q12']\n",
    "participant_data['hand'] = post_csv['Q14']\n",
    "participant_data['motion_sick'] = post_csv['Q2']\n",
    "participant_data['pre_ssq'] = (pre_n_raw + pre_o_raw + pre_d_raw) * 3.74\n",
    "participant_data['post_ssq'] = (post_n_raw + post_o_raw + post_d_raw) * 3.74\n",
    "participant_data['delta_ssq'] = participant_data['post_ssq'] - participant_data['pre_ssq']\n",
    "participant_data['crt_pref'] = post_csv['Q4']\n",
    "participant_data['nav_pref'] = post_csv['Q6']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "participant_data.to_pickle('participant_data.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
